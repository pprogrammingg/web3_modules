(function() {
    var g1 = [
        { question: "Why must gossip happen before or with the state-machine SubmitTransaction event?", options: ["To reduce latency", "So other validators receive the tx and can add it to their mempools; if a validator adds to mempool but never gossips, other shards never see the tx", "To satisfy the RPC client", "Gossip is optional"], correct: 1, explanation: "Gossip is how the tx reaches all involved shards. If a validator only adds to its mempool and never gossips, other shards never get the tx and it cannot be proposed everywhere." },
        { question: "When is involves_local_shard(tx) false for a validator?", options: ["When the validator is the proposer", "When the tx's declared_reads and declared_writes touch no NodeIds that map to this validator's shard", "When the mempool is full", "When the tx is cross-shard"], correct: 1, explanation: "The node only calls mempool.on_transaction_gossip_arc when topology.involves_local_shard(tx) is true; otherwise this shard has no part in the tx." },
        { question: "What does submitted_locally: true vs false indicate in a PoolEntry?", options: ["Whether the tx was committed", "Whether this validator received the tx via RPC (true) or via gossip from another node (false)", "Whether the tx is single-shard", "Whether the tx is priority"], correct: 1, explanation: "The code tracks whether the tx was submitted at this node (RPC) or received via gossip so it can handle status and gossip behavior correctly." },
        { question: "Why is is_cross_shard defined only from declared_writes and not declared_reads?", options: ["declared_reads are not available", "Only write shards need to agree on ordering and commit; including read-only shards in 'cross-shard' would change mempool/BFT behavior incorrectly", "Reads are always local", "It is a bug"], correct: 1, explanation: "Consensus and commit ordering are about write shards; read-only shards are provisioning shards. Using declared_reads in is_cross_shard would misclassify txs." },
        { question: "If the RPC handler returns 202 Accepted, does that guarantee the transaction will eventually be proposed?", options: ["Yes, always", "No; conditions like mempool full, gossip failure, or the tx not involving this node's shard can prevent it from ever entering a block", "Only for single-shard txs", "Only if the node is the proposer"], correct: 1, explanation: "202 Accepted means the node accepted the submission; it does not guarantee the tx will be proposed (mempool limits, backpressure, or shard involvement can prevent it)." },
        { question: "How does the runner decide which shards are 'relevant' for gossiping a given transaction?", options: ["It gossips to all validators", "Using the set of shards that have an interest (e.g. consensus_shards ∪ provisioning_shards / all_shards_for_transaction), computed from the tx's declared reads/writes in types/topology", "The proposer decides", "Only the local shard"], correct: 1, explanation: "Relevant shards are derived from the tx's NodeIds and topology (e.g. all_shards_for_transaction); that set is computed in types and used by the runner for gossip targets." },
        { question: "When a validator receives TransactionGossipReceived for a tx it already has in the mempool (same hash), what does the mempool do?", options: ["Rejects the duplicate", "Updates the entry (e.g. merge gossip info) or ignores; avoids duplicate work and keeps state consistent", "Removes the old entry", "Forwards to the proposer only"], correct: 1, explanation: "The mempool typically deduplicates by hash and may update metadata; it does not insert a second copy, keeping one entry per tx hash." },
        { question: "At 'first contact' (submit or gossip receive), what status is emitted via EmitTransactionStatus?", options: ["Completed", "Committed", "Pending (or similar); it may differ for the submitting node vs others depending on implementation", "Executed"], correct: 2, explanation: "When the tx is first received, status is Pending (or equivalent). Submitting node vs others might differ if the implementation tracks 'submitted here' separately." },
        { question: "Are transactions from RPC and from gossip encoded and sent over the network in the same message type?", options: ["No, RPC uses a different protocol", "Yes; typically the same message type (e.g. TransactionGossip) is used so that gossip and RPC-submitted txs are forwarded the same way; the type is defined in messages crate", "Only for cross-shard", "RPC transactions are never gossiped"], correct: 1, explanation: "Production/messages define the wire format; usually one message type is used for both so that any node can forward the tx to relevant shards." },
        { question: "If the mempool is at rpc_mempool_limit, what happens to a new RPC submission?", options: ["It is queued indefinitely", "The submission is rejected or backpressured (e.g. 503); the same tx arriving via gossip on the same node would also be rejected if the pool is full", "Only gossip is rejected", "The oldest tx is evicted"], correct: 1, explanation: "At capacity, new submissions (RPC or gossip) are rejected or backpressured so the node does not exceed its limits; the exact behavior is in mempool." }
    ];
    var g2 = [
        { question: "consensus_shards(tx) is the set of shards of declared_writes; provisioning_shards(tx) is the set of shards of declared_reads not in the write set. Can provisioning_shards be non-empty while consensus_shards has exactly one shard?", options: ["No", "Yes; e.g. a tx that writes to one shard but reads from another (read-only) shard; it is still cross-shard for execution because the executor may need provisions from the read shard", "Only for read-only txs", "provisioning_shards is always empty"], correct: 1, explanation: "Example: writes to shard 1 only, reads from shard 2. consensus_shards = {1}, provisioning_shards = {2}. The executor on shard 1 may need state from shard 2." },
        { question: "If a transaction has declared_writes empty (read-only), how does is_cross_shard behave?", options: ["It is always true", "It is false (no write shards); that is the right rule for mempool and BFT so read-only txs are not treated as multi-shard for ordering", "It throws an error", "It is true if declared_reads has more than one shard"], correct: 1, explanation: "is_cross_shard is defined from declared_writes only; read-only txs have no write shards so are single-shard for consensus purposes." },
        { question: "Why does shard_for_node(node_id, num_shards) use a hash of the NodeId rather than e.g. the first byte?", options: ["To save space", "To get a uniform distribution across shards and avoid bias (first byte could be correlated); hash gives deterministic but well-spread assignment", "The first byte is used for something else", "It doesn't use a hash"], correct: 1, explanation: "A hash (e.g. blake3) of the NodeId gives deterministic, uniform shard assignment; raw bytes could skew load." },
        { question: "Can the same NodeId ever map to different shards on two validators?", options: ["Yes, always", "Under normal static topology, no; under epoch change or shard split, the mapping might change so 'the shard for this NodeId' can change", "Only during view change", "No, never"], correct: 1, explanation: "With static topology everyone agrees. If the protocol supports dynamic topology (epoch/shard split), the mapping can change." },
        { question: "When would the submitting validator not add the tx to its own mempool?", options: ["Never", "When involves_local_shard(tx) is false for that validator (e.g. the tx only touches other shards); the tx still gets proposed because it was gossiped to and stored in the mempools of the involved shards", "When the tx is too large", "When the mempool is full"], correct: 1, explanation: "If the submitter's shard is not in the tx's shard set, the node does not add it locally; other nodes that are in involved shards received it via gossip and have it in their mempools." },
        { question: "Is all_shards_for_transaction(tx) always exactly consensus_shards ∪ provisioning_shards?", options: ["No, it can include extra shards", "Yes, by definition it is the union used for gossip targets and coordination", "Only for single-shard txs", "It is only consensus_shards"], correct: 1, explanation: "all_shards_for_transaction is the union of consensus and provisioning shards, used for gossip and for knowing all participants." },
        { question: "Why does the codebase use ShardGroupId instead of raw u64 for shard identity?", options: ["To save memory", "Type safety and clear semantics; the conversion from validator index to ShardGroupId for static topology is defined in types/topology", "Raw u64 is not supported", "For hashing only"], correct: 1, explanation: "ShardGroupId is a distinct type so the compiler prevents mixing with other ids; topology defines how validator index maps to ShardGroupId." },
        { question: "Is there a single method in types/topology that returns 'target shard' for execution?", options: ["Yes, target_shard(tx)", "Usually you derive it from consensus_shards/provisioning_shards; the derivation (who executes vs who provisions) is in execution/provisions code", "Only in the BFT crate", "target is always the local shard"], correct: 1, explanation: "Topology gives consensus_shards and provisioning_shards; execution and provisions crates define which shard is target (executor) vs source (provisioner)." },
        { question: "If num_shards is 1, what happens to provisioning_shards and cross-shard 2PC?", options: ["Both are disabled", "Every NodeId maps to shard 0; provisioning_shards can still be non-empty if there are read-only shards (but with one shard there is only shard 0); cross-shard 2PC is effectively a no-op (one shard)", "2PC always runs", "provisioning_shards is undefined"], correct: 1, explanation: "With one shard, all state is on shard 0; no cross-shard 2PC in practice; provisioning may still be used for consistency." },
        { question: "Does BFT ever need to know about a remote shard's chain or state?", options: ["Yes, always", "Generally no for local BFT; cross-shard awareness appears at the node/execution/provisions boundary (e.g. waiting for provisions from other shards), not inside BFT itself", "Yes, for QC aggregation", "Only the proposer does"], correct: 1, explanation: "BFT is per-shard. Cross-shard coordination is in execution and provisions; the node composes BFT with those." }
    ];
    var g3 = [
        { question: "Why must the mempool be told about pending (uncommitted) block contents when calling ready_transactions?", options: ["To speed up proposal", "So it does not return txs that are already in pending blocks (invariant: same tx not in two in-flight blocks); using (0,0) would break that", "To reserve capacity", "It is optional"], correct: 1, explanation: "pending_txs and pending_certs tell the mempool what is already in the pipeline so it excludes those from ready_transactions." },
        { question: "Why can't the proposer always use 'current local JMT root' instead of the parent block's header for BuildProposal?", options: ["It can always use current", "Because the block must extend from the committed chain; the parent block's state_root is what validators will verify; using current JMT could diverge if local state is ahead", "JMT is not used", "Only the runner has JMT access"], correct: 1, explanation: "The proposal must reference the parent block's state so all validators agree on the chain; current local JMT might include uncommitted state." },
        { question: "What is the exact order of sections in a block (retry / priority / normal / certificates / deferred / aborted)?", options: ["Random", "Defined in the BFT or block-building code; typically retries first, then priority, then others, then certificates, then deferred, then aborted", "Only transactions then certificates", "Certificates first"], correct: 1, explanation: "The order is enforced in code (bft or types) so that replay and deferral handling are deterministic." },
        { question: "If the proposer is syncing (syncing == true), what kind of block does it build?", options: ["A full block with txs and certificates", "An empty or minimal block (e.g. no transactions, or only sync-related content); exact content is in bft/build logic", "Same as normal", "It does not build"], correct: 1, explanation: "When syncing, the proposer usually builds a block that does not include normal tx flow so the chain can catch up." },
        { question: "What makes a tx 'priority' vs 'others' in ready_transactions?", options: ["Size", "Priority is typically for retries or time-sensitive txs; priority txs can bypass the soft in-flight limit so they are not starved", "Fee", "Random"], correct: 1, explanation: "Priority is a mempool classification (e.g. retries, or implementation-defined); they get preferred treatment in the ready set." },
        { question: "If the designated proposer is slow or partitioned, how does the chain eventually advance?", options: ["It doesn't", "A round/timeout mechanism (e.g. ProposalTimer) drives round change; when the timer fires or enough nodes timeout, the round advances and a new proposer is chosen", "The next validator proposes", "Manual intervention"], correct: 1, explanation: "BFT uses round timers and timeouts; when the round advances, (height, round) changes and a new proposer is selected." },
        { question: "What are commitment_proofs used for in BuildProposal?", options: ["Nothing", "They prove that certain txs (e.g. cross-shard) have commitment from source shards; the execution/provisions component builds them before the proposal", "Only for single-shard", "For QC aggregation"], correct: 1, explanation: "Commitment proofs are built when provisions are aggregated; the proposer includes them in the block so the block is valid." },
        { question: "Deferrals in a block must have a CycleProof with enough signers. Where does the proposer filter weak CycleProofs?", options: ["In the mempool", "In the bft or block-building path; a block with a weak CycleProof would be rejected by validators (verification in bft/types)", "Nowhere", "In execution only"], correct: 1, explanation: "The proposer only includes deferrals that have a valid CycleProof; validators verify and reject blocks with insufficient proof." },
        { question: "At proposal time, does the proposer compute the new state root by applying certificates to the parent state?", options: ["Yes, always", "Either the proposer or the runner does it inside BuildProposal; the contract (who computes it) is in the bft/runner code and comments", "The execution crate does it", "State root is not in the block"], correct: 1, explanation: "BuildProposal needs the new state root; the implementation (proposer vs runner) is documented in the code." },
        { question: "Where are the maximum number of certificates and transactions per block configured and enforced?", options: ["Only at runtime", "In types or bft (block size limits, max_txs, max_certs); enforced when building and when verifying the block", "In the mempool only", "There are no limits"], correct: 1, explanation: "Block structure and limits are in types; bft and verification enforce them when building and validating blocks." }
    ];
    var g4 = [
        { question: "Why is a block B committed only when a child block has a QC (2-chain rule), not as soon as B has a QC?", options: ["To reduce messages", "So that the chain is safe: committing only when the next block certifies B ensures that 2f+1 validators have moved on; committing on B's QC alone could allow equivocation at the same height", "To speed up finality", "It is arbitrary"], correct: 1, explanation: "The 2-chain rule ensures that when we commit B, we have a child block with QC, so the chain has progressed and equivocation at height of B is resolved." },
        { question: "Where is the 'wait for JMT at parent state root' before block verification implemented?", options: ["In the mempool", "In an action or event handler (e.g. the runner or bft waits for state sync); if the wait times out, the block may be dropped or round advanced", "Nowhere", "In execution only"], correct: 1, explanation: "Block verification needs the parent state root to be present in JMT; the runner/bft implements the wait and timeout." },
        { question: "What attack becomes possible if we skipped VerifyQcSignature and a malicious proposer could include a block with a fake QC?", options: ["None", "The proposer could forge a QC that was never signed by 2f+1 validators, so the chain could commit blocks without real agreement (safety violation)", "Only liveness is affected", "Double spend only"], correct: 1, explanation: "VerifyQcSignature ensures the QC is genuine; without it, an attacker could fake consensus and break BFT safety." },
        { question: "Why must vote persistence complete before the vote is sent (PersistAndBroadcastVote)?", options: ["To reduce latency", "So that after a crash, the node has the vote persisted and can recover; if we sent before persisting, we might send then crash and lose the vote", "It is not required", "To batch writes"], correct: 1, explanation: "Persistence-before-send ensures the vote is durable; otherwise a crash could lose the vote after sending, causing inconsistency." },
        { question: "After BlockCommitted, does BFT update its committed height in the same event handling path as when execution runs?", options: ["No", "Yes; if execution ran before BFT updated committed height, the node could propose or vote on blocks that extend from the wrong height", "Execution runs first always", "They are independent"], correct: 1, explanation: "The order of updates (BFT committed height vs dispatching to execution) matters for consistency; both happen in the same path with defined order." },
        { question: "If two blocks at the same height get quorum (e.g. view change, equivocation), how does the protocol ensure only one commit?", options: ["It doesn't", "The 2-chain rule and the way 'committed block' is uniquely determined (e.g. by parent chain) ensure only one block at that height is committed; the logic is in bft state", "By ignoring the second", "By re-voting"], correct: 1, explanation: "Commit rule and chain advancement in bft state ensure that at most one block per height is committed." },
        { question: "Why does the signing message for a block vote include round and not only height and block_hash?", options: ["To make the message longer", "So that votes for the same height but different rounds are distinct; round is part of the protocol state and prevents replay across rounds", "Round is optional", "For debugging"], correct: 1, explanation: "Including round in the signed message binds the vote to that round and prevents reuse in another round." },
        { question: "When quorum is not yet reached after VerifyAndBuildQuorumCertificate, what does the state machine receive back?", options: ["Nothing", "A partial result or event (e.g. collected votes, or 'not enough'); the state machine uses it to avoid re-verifying the same votes later", "An error", "The same QC"], correct: 1, explanation: "The action can return partial state (e.g. verified votes so far) so the node does not re-verify when more votes arrive." },
        { question: "How is the parent of the first real block (height 1) represented in BFT state and in the block header?", options: ["There is no parent", "Genesis block has a special QC; the parent of height 1 is genesis, represented in the header and in BFT state (e.g. genesis_qc or similar)", "As null", "As height 0 only"], correct: 1, explanation: "Genesis is a special block/QC; block at height 1 references it as parent in header and BFT state." },
        { question: "When a node is behind and receives SyncBlockReadyToApply, does it commit blocks one by one through the same 2-chain logic?", options: ["No", "There can be a separate sync path that applies multiple blocks (e.g. batch) or the same 2-chain logic; the distinction is in bft/sync code", "Sync does not commit", "It only downloads"], correct: 1, explanation: "Sync may use the same commit rule or a dedicated path; the code in bft/sync shows how syncing commits blocks." }
    ];
    var g5 = [
        { question: "When on_block_committed runs, is the partition into single-shard vs cross-shard the same as !tx.is_cross_shard(num_shards)?", options: ["Always identical", "It should be the same notion; the partition is done in execution (on_block_committed) using the types' definition or a local helper", "Execution uses a different rule", "Only single-shard is partitioned"], correct: 1, explanation: "Execution partitions by single- vs cross-shard; that should align with types' is_cross_shard so the same txs are handled consistently." },
        { question: "How does execution state know to skip re-execution when speculative votes were already sent?", options: ["It always re-executes", "It tracks which txs/blocks already had speculative execution (e.g. in state or via events); that state is updated when speculative votes are sent and checked when the block commits", "It doesn't skip", "Only the proposer skips"], correct: 1, explanation: "Speculative execution is tracked so that on commit we do not re-run and re-vote for the same block." },
        { question: "At which exact event does the mempool transition from Committed to Executed?", options: ["BlockCommitted", "When the execution layer emits TransactionExecuted; the node consumes it and updates mempool status to Executed", "When the certificate is built", "On finality"], correct: 1, explanation: "TransactionExecuted is emitted by execution; the node passes it to the mempool which updates the tx status to Executed." },
        { question: "Why are state writes from a TransactionCertificate applied only when the certificate is in a committed block, not as soon as the certificate is built?", options: ["To reduce I/O", "So that the chain has agreed on the certificate (it is in a block that passed BFT); applying earlier would make state visible before consensus", "To batch writes", "Certificates are not in blocks"], correct: 1, explanation: "State is applied only after the certificate is committed in a block so that all nodes apply in the same order and only to agreed outcomes." },
        { question: "If one shard's execution rejects (success=false), how is that reflected in the final TransactionCertificate and mempool status?", options: ["It is ignored", "The TransactionCertificate reflects the rejection (e.g. success=false); the mempool marks the tx as failed or aborted", "Only the executor shard knows", "The block is invalid"], correct: 1, explanation: "Aggregation of StateCertificates produces a TransactionCertificate; if any shard rejected, the tx outcome is failure and mempool is updated accordingly." },
        { question: "Who consumes TransactionExecuted and what do they do with it?", options: ["Only execution", "The node consumes it and passes it to mempool (and possibly BFT); mempool updates status to Executed, and the node may trigger certificate aggregation or other actions", "Only mempool", "No one"], correct: 1, explanation: "NodeStateMachine receives TransactionExecuted and forwards to mempool and possibly other state machines." },
        { question: "Is execution triggered synchronously in the same call stack as block-committed handling, or asynchronously?", options: ["Always synchronous", "Implementation-dependent; it can be synchronous (same stack) or the runner can emit an event to run execution later; the node/bft code shows which", "Always asynchronous", "Only for cross-shard"], correct: 1, explanation: "The runner and node design decide whether execution runs in the same call path or via a follow-up event." },
        { question: "Where does the engine's execute_single_shard get its storage snapshot state root from?", options: ["Current JMT head", "Parent block (or committed state at that block); so execution is deterministic from the committed chain", "The proposer's state", "Latest speculative state"], correct: 1, explanation: "Execution uses the state at the committed block (parent or agreed snapshot) so all validators get the same result." },
        { question: "Is StateVoteBlock aggregation to StateCertificate done inside the execution crate or in the node/BFT?", options: ["Only in execution", "The execution crate produces StateVoteBlock; the node or BFT emits AggregateStateCertificate and the runner performs aggregation; the exact place is in node or bft", "Only in BFT", "In the engine"], correct: 1, explanation: "Aggregation is an action (AggregateStateCertificate); the state machine that emits it is in node or bft; the runner runs the aggregation." },
        { question: "When a block commits, execution receives all transactions in the block. How does it avoid running txs that don't involve the local shard?", options: ["It runs all of them", "It filters by involves_local_shard or equivalent (only runs/votes on txs that touch this shard)", "The proposer only includes local txs", "It doesn't avoid it"], correct: 1, explanation: "Execution only runs and votes on transactions that involve the local shard; others are skipped." }
    ];
    var g6 = [
        { question: "Who decides which validators on the source shard send StateProvision to the target?", options: ["Only the proposer", "Typically every validator (or a defined subset) that committed the block sends provisions; the logic is in execution/provisions (who sends)", "Only the leader", "The target requests them"], correct: 1, explanation: "Provisions are sent by validators on the source shard; the exact rule (all or subset) is in provisions/execution." },
        { question: "What must 'match' for 2f+1 provisions from a source shard to be aggregated?", options: ["Only tx_hash", "Same tx_hash, same entries (or state), and consistent block_height (or equivalent); if 2f+1 have different entries, it's a fault", "Only block height", "Nothing"], correct: 1, explanation: "Provisions must be for the same tx and consistent state; mismatch in entries would indicate a bug or attack." },
        { question: "Why is VerifyAndAggregateProvisions deferred until enough provisions are buffered (quorum), rather than verifying each as it arrives?", options: ["To reduce CPU", "Efficiency (batch verify) and/or correctness (e.g. need quorum to decide which version is correct); verifying one-by-one might be wasteful or ambiguous", "To save memory", "It isn't deferred"], correct: 1, explanation: "Deferred verification allows batch verification and ensures we only commit when we have a quorum of matching provisions." },
        { question: "When the proposer includes a TransactionDefer in a block, what must the block also include so validators accept it?", options: ["Nothing", "A CycleProof (or equivalent) with enough signers proving the cycle/deferral is valid", "Only the tx hash", "A QC"], correct: 1, explanation: "Deferrals require a proof (e.g. CycleProof) so that all validators agree the deferral was justified." },
        { question: "After a tx is deferred, where is the retry transaction (same payload, different hash) created?", options: ["In the wallet", "In the livelock or execution crate; the mempool treats the original as deferred and the retry as a new tx for status and eviction", "In the mempool only", "In BFT"], correct: 1, explanation: "Retry creation is in livelock/execution; mempool tracks original vs retry for status and eviction." },
        { question: "How does the protocol pick a 'winner' and 'loser' in a cycle (e.g. A waits on B, B waits on A)?", options: ["Random", "Deterministic ordering (e.g. by tx hash or shard order) is defined in livelock so all nodes agree who defers", "The proposer chooses", "First-come first-served"], correct: 1, explanation: "Cycle resolution is deterministic (e.g. hash-based or shard-based) so all validators defer the same tx." },
        { question: "Where is CommitmentProof first created and who includes it in a block?", options: ["In the block only", "Created by the action that aggregates provisions (e.g. VerifyAndAggregateProvisions result); the proposer for the shard that needs the proof includes it in the block", "In execution only", "In types only"], correct: 1, explanation: "CommitmentProof is the result of aggregating 2f+1 provisions; the proposer for the target (or relevant) shard includes it in the block." },
        { question: "For a cross-shard tx with three participating shards (two source, one target), how many StateProvision flows and how many StateCertificates for the TransactionCertificate?", options: ["1 flow, 1 certificate", "Two source→target flows (each source sends to target); we need StateCertificates from each participating shard (e.g. 3) to build the TransactionCertificate", "3 flows, 1 certificate", "2 flows, 2 certificates"], correct: 1, explanation: "Each source shard sends provisions to the target; the target (and possibly others) produce StateCertificates; all are aggregated into one TransactionCertificate." },
        { question: "Can provisions for a cross-shard tx arrive before the block that contains the tx commits?", options: ["No", "Yes (e.g. optimistic or mistaken sender); the coordinator buffers or ignores early arrivals until the block commits and registration is done", "Only from the same height", "Provisions are always after commit"], correct: 1, explanation: "Provisions might arrive early; the provision coordinator tracks by tx and only uses them after the block is committed and the tx is registered." },
        { question: "When a block contains both a deferred tx and the winner tx's certificate, in what order must the node process them?", options: ["Certificate first", "The order is enforced in code (e.g. deferral before certificate, or the reverse) so that mempool and state stay consistent; it's in execution/node", "Any order", "Deferral first always"], correct: 1, explanation: "The application order of deferrals vs certificates is fixed in the node/execution so that retry and completion are handled correctly." }
    ];

    // Quick Test: one question per flow stage (tx submission → cross-shard)
    var quickTest = [
        { question: "Where does a submitted transaction first enter the system and get gossiped to relevant shards?", options: ["hyperscale-bft only", "hyperscale-production (RPC, runner) and hyperscale-messages (TransactionGossip); production dispatches to state machine and gossips", "hyperscale-execution only", "hyperscale-mempool only"], correct: 1, explanation: "Production has the RPC handler and runner; it submits to the state machine and gossips via messages. Mempool receives the event after." },
        { question: "Which crates define which shard(s) a transaction touches and where it is stored?", options: ["hyperscale-bft and hyperscale-mempool", "hyperscale-types (Topology, consensus_shards, provisioning_shards, RoutableTransaction) and hyperscale-node (routing by involves_local_shard)", "hyperscale-execution only", "hyperscale-provisions only"], correct: 1, explanation: "Types has topology and shard helpers; the node uses them to route events to the right shards and mempools." },
        { question: "Who selects the proposer and assembles the next block from the mempool?", options: ["hyperscale-execution", "hyperscale-bft (proposer selection, BuildProposal) and hyperscale-mempool (ready_transactions); types and core define Block and actions", "hyperscale-messages only", "hyperscale-provisions"], correct: 1, explanation: "BFT chooses the proposer and requests ready txs from mempool; it builds the block with parent state and certificates." },
        { question: "How do validators agree on a block and when is it committed?", options: ["hyperscale-mempool decides", "hyperscale-bft (verification, BlockVote, VerifyAndBuildQuorumCertificate, 2-chain rule, BlockCommitted); types has QC and BlockHeader; core has the actions", "hyperscale-execution commits", "hyperscale-livelock"], correct: 1, explanation: "BFT collects votes, builds QC, and applies the 2-chain commit rule; types and core define the certificate and actions." },
        { question: "After a block is committed, who runs transactions and how do single-shard vs cross-shard paths split?", options: ["hyperscale-bft runs execution", "hyperscale-execution (on_block_committed, single-shard execution, cross-shard registration), hyperscale-engine (Radix), node (dispatches BlockCommitted, handles TransactionExecuted); types and core have StateVoteBlock, StateCertificate, actions", "hyperscale-mempool executes", "hyperscale-messages"], correct: 1, explanation: "Execution runs on commit; engine does Radix execution; node dispatches and handles certificate feedback." },
        { question: "How does state move between shards for cross-shard transactions and how is deadlock avoided?", options: ["hyperscale-bft sends state", "hyperscale-provisions (StateProvision, quorum, CommitmentProof), hyperscale-execution (2PC phases), hyperscale-livelock (cycle detection, deferral, retry); types and core have StateProvision, CycleProof, actions", "hyperscale-mempool only", "hyperscale-messages"], correct: 1, explanation: "Provisions sends state to target shard; execution runs 2PC; livelock detects cycles and defers/retries to avoid deadlock." }
    ];

    initializeQuiz('quiz-group-1', g1, 70);
    initializeQuiz('quiz-group-2', g2, 70);
    initializeQuiz('quiz-group-3', g3, 70);
    initializeQuiz('quiz-group-4', g4, 70);
    initializeQuiz('quiz-group-5', g5, 70);
    initializeQuiz('quiz-group-6', g6, 70);
    initializeQuiz('quiz-quick-test', quickTest, 70);
})();
